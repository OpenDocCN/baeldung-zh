["```\r\n<dependencies>\r\n    <dependency>\r\n        <groupId>org.apache.spark</groupId>\r\n\t<artifactId>spark-core_2.10</artifactId>\r\n\t<version>1.6.0</version>\r\n    </dependency>\r\n</dependencies>\r\n```","```\r\npublic static void main(String[] args) throws Exception {\r\n    if (args.length < 1) {\r\n        System.err.println(\"Usage: JavaWordCount <file>\");\r\n        System.exit(1);\r\n    }\r\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaWordCount\");\r\n    JavaSparkContext ctx = new JavaSparkContext(sparkConf);\r\n    JavaRDD<String> lines = ctx.textFile(args[0], 1);\r\n\r\n    JavaRDD<String> words \r\n      = lines.flatMap(s -> Arrays.asList(SPACE.split(s)).iterator());\r\n    JavaPairRDD<String, Integer> ones \r\n      = words.mapToPair(word -> new Tuple2<>(word, 1));\r\n    JavaPairRDD<String, Integer> counts \r\n      = ones.reduceByKey((Integer i1, Integer i2) -> i1 + i2);\r\n\r\n    List<Tuple2<String, Integer>> output = counts.collect();\r\n    for (Tuple2<?, ?> tuple : output) {\r\n        System.out.println(tuple._1() + \": \" + tuple._2());\r\n    }\r\n    ctx.stop();\r\n}\r\n```","```\r\n${spark-install-dir}/bin/spark-submit --class com.baeldung.WordCount \r\n  --master local ${WordCount-MavenProject}/target/apache-spark-1.0-SNAPSHOT.jar\r\n  ${WordCount-MavenProject}/src/main/resources/spark_example.txt\r\n```","```\r\nHello 1\r\nfrom 2\r\nBaledung 2\r\nKeep 1\r\nLearning 1\r\nSpark 1\r\nBye 1\r\n```"]
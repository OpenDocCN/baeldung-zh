["```\r\n<dependency>\r\n    <groupId>org.apache.opennlp</groupId>\r\n    <artifactId>opennlp-tools</artifactId>\r\n    <version>1.8.4</version>\r\n</dependency>\r\n```","```\r\n@Test\r\npublic void givenEnglishModel_whenDetect_thenSentencesAreDetected() \r\n  throws Exception {\r\n\r\n    String paragraph = \"This is a statement. This is another statement.\" \r\n      + \"Now is an abstract word for time, \"\r\n      + \"that is always flying. And my email address is [[email protected]](/web/20220724194915/https://www.baeldung.com/cdn-cgi/l/email-protection)\";\r\n\r\n    InputStream is = getClass().getResourceAsStream(\"/models/en-sent.bin\");\r\n    SentenceModel model = new SentenceModel(is);\r\n\r\n    SentenceDetectorME sdetector = new SentenceDetectorME(model);\r\n\r\n    String sentences[] = sdetector.sentDetect(paragraph);\r\n    assertThat(sentences).contains(\r\n      \"This is a statement.\",\r\n      \"This is another statement.\",\r\n      \"Now is an abstract word for time, that is always flying.\",\r\n      \"And my email address is [[email protected]](/web/20220724194915/https://www.baeldung.com/cdn-cgi/l/email-protection)\");\r\n}\r\n```","```\r\n@Test\r\npublic void givenEnglishModel_whenTokenize_thenTokensAreDetected() \r\n  throws Exception {\r\n\r\n    InputStream inputStream = getClass()\r\n      .getResourceAsStream(\"/models/en-token.bin\");\r\n    TokenizerModel model = new TokenizerModel(inputStream);\r\n    TokenizerME tokenizer = new TokenizerME(model);\r\n    String[] tokens = tokenizer.tokenize(\"Baeldung is a Spring Resource.\");\r\n\r\n    assertThat(tokens).contains(\r\n      \"Baeldung\", \"is\", \"a\", \"Spring\", \"Resource\", \".\");\r\n}\r\n```","```\r\n@Test\r\npublic void givenWhitespaceTokenizer_whenTokenize_thenTokensAreDetected() \r\n  throws Exception {\r\n\r\n    WhitespaceTokenizer tokenizer = WhitespaceTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer.tokenize(\"Baeldung is a Spring Resource.\");\r\n\r\n    assertThat(tokens)\r\n      .contains(\"Baeldung\", \"is\", \"a\", \"Spring\", \"Resource.\");\r\n  }\r\n```","```\r\n@Test\r\npublic void givenSimpleTokenizer_whenTokenize_thenTokensAreDetected() \r\n  throws Exception {\r\n\r\n    SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer\r\n      .tokenize(\"Baeldung is a Spring Resource.\");\r\n\r\n    assertThat(tokens)\r\n      .contains(\"Baeldung\", \"is\", \"a\", \"Spring\", \"Resource\", \".\");\r\n  }\r\n```","```\r\n@Test\r\npublic void \r\n  givenEnglishPersonModel_whenNER_thenPersonsAreDetected() \r\n  throws Exception {\r\n\r\n    SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer\r\n      .tokenize(\"John is 26 years old. His best friend's \"  \r\n        + \"name is Leonard. He has a sister named Penny.\");\r\n\r\n    InputStream inputStreamNameFinder = getClass()\r\n      .getResourceAsStream(\"/models/en-ner-person.bin\");\r\n    TokenNameFinderModel model = new TokenNameFinderModel(\r\n      inputStreamNameFinder);\r\n    NameFinderME nameFinderME = new NameFinderME(model);\r\n    List<Span> spans = Arrays.asList(nameFinderME.find(tokens));\r\n\r\n    assertThat(spans.toString())\r\n      .isEqualTo(\"[[0..1) person, [13..14) person, [20..21) person]\");\r\n}\r\n```","```\r\n@Test\r\npublic void givenPOSModel_whenPOSTagging_thenPOSAreDetected() \r\n  throws Exception {\r\n\r\n    SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer.tokenize(\"John has a sister named Penny.\");\r\n\r\n    InputStream inputStreamPOSTagger = getClass()\r\n      .getResourceAsStream(\"/models/en-pos-maxent.bin\");\r\n    POSModel posModel = new POSModel(inputStreamPOSTagger);\r\n    POSTaggerME posTagger = new POSTaggerME(posModel);\r\n    String tags[] = posTagger.tag(tokens);\r\n\r\n    assertThat(tags).contains(\"NNP\", \"VBZ\", \"DT\", \"NN\", \"VBN\", \"NNP\", \".\");\r\n}\r\n```","```\r\n@Test\r\npublic void givenEnglishDictionary_whenLemmatize_thenLemmasAreDetected() \r\n  throws Exception {\r\n\r\n    SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer.tokenize(\"John has a sister named Penny.\");\r\n\r\n    InputStream inputStreamPOSTagger = getClass()\r\n      .getResourceAsStream(\"/models/en-pos-maxent.bin\");\r\n    POSModel posModel = new POSModel(inputStreamPOSTagger);\r\n    POSTaggerME posTagger = new POSTaggerME(posModel);\r\n    String tags[] = posTagger.tag(tokens);\r\n    InputStream dictLemmatizer = getClass()\r\n      .getResourceAsStream(\"/models/en-lemmatizer.dict\");\r\n    DictionaryLemmatizer lemmatizer = new DictionaryLemmatizer(\r\n      dictLemmatizer);\r\n    String[] lemmas = lemmatizer.lemmatize(tokens, tags);\r\n\r\n    assertThat(lemmas)\r\n      .contains(\"O\", \"have\", \"a\", \"sister\", \"name\", \"O\", \"O\");\r\n}\r\n```","```\r\n@Test\r\npublic void \r\n  givenChunkerModel_whenChunk_thenChunksAreDetected() \r\n  throws Exception {\r\n\r\n    SimpleTokenizer tokenizer = SimpleTokenizer.INSTANCE;\r\n    String[] tokens = tokenizer.tokenize(\"He reckons the current account \r\n      deficit will narrow to only 8 billion.\");\r\n\r\n    InputStream inputStreamPOSTagger = getClass()\r\n      .getResourceAsStream(\"/models/en-pos-maxent.bin\");\r\n    POSModel posModel = new POSModel(inputStreamPOSTagger);\r\n    POSTaggerME posTagger = new POSTaggerME(posModel);\r\n    String tags[] = posTagger.tag(tokens);\r\n\r\n    InputStream inputStreamChunker = getClass()\r\n      .getResourceAsStream(\"/models/en-chunker.bin\");\r\n    ChunkerModel chunkerModel\r\n     = new ChunkerModel(inputStreamChunker);\r\n    ChunkerME chunker = new ChunkerME(chunkerModel);\r\n    String[] chunks = chunker.chunk(tokens, tags);\r\n    assertThat(chunks).contains(\r\n      \"B-NP\", \"B-VP\", \"B-NP\", \"I-NP\", \r\n      \"I-NP\", \"I-NP\", \"B-VP\", \"I-VP\", \r\n      \"B-PP\", \"B-NP\", \"I-NP\", \"I-NP\", \"O\");\r\n}\r\n```","```\r\n@Test\r\npublic void \r\n  givenLanguageDictionary_whenLanguageDetect_thenLanguageIsDetected() \r\n  throws FileNotFoundException, IOException {\r\n\r\n    InputStreamFactory dataIn\r\n     = new MarkableFileInputStreamFactory(\r\n       new File(\"src/main/resources/models/DoccatSample.txt\"));\r\n    ObjectStream lineStream = new PlainTextByLineStream(dataIn, \"UTF-8\");\r\n    LanguageDetectorSampleStream sampleStream\r\n     = new LanguageDetectorSampleStream(lineStream);\r\n    TrainingParameters params = new TrainingParameters();\r\n    params.put(TrainingParameters.ITERATIONS_PARAM, 100);\r\n    params.put(TrainingParameters.CUTOFF_PARAM, 5);\r\n    params.put(\"DataIndexer\", \"TwoPass\");\r\n    params.put(TrainingParameters.ALGORITHM_PARAM, \"NAIVEBAYES\");\r\n\r\n    LanguageDetectorModel model = LanguageDetectorME\r\n      .train(sampleStream, params, new LanguageDetectorFactory());\r\n\r\n    LanguageDetector ld = new LanguageDetectorME(model);\r\n    Language[] languages = ld\r\n      .predictLanguages(\"estava em uma marcenaria na Rua Bruno\");\r\n    assertThat(Arrays.asList(languages))\r\n      .extracting(\"lang\", \"confidence\")\r\n      .contains(\r\n        tuple(\"pob\", 0.9999999950605625),\r\n        tuple(\"ita\", 4.939427661577956E-9), \r\n        tuple(\"spa\", 9.665954064665144E-15),\r\n        tuple(\"fra\", 8.250349924885834E-25)));\r\n}\r\n```"]
["```\r\nprivate AdminClient getAdminClient(String bootstrapServerConfig) {\r\n    Properties config = new Properties();\r\n    config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServerConfig);\r\n    return AdminClient.create(config);\r\n}\r\n```","```\r\nprivate Map<TopicPartition, Long> getConsumerGrpOffsets(String groupId) \r\n  throws ExecutionException, InterruptedException {\r\n    ListConsumerGroupOffsetsResult info = adminClient.listConsumerGroupOffsets(groupId);\r\n    Map<TopicPartition, OffsetAndMetadata> topicPartitionOffsetAndMetadataMap = info.partitionsToOffsetAndMetadata().get();\r\n\r\n    Map<TopicPartition, Long> groupOffset = new HashMap<>();\r\n    for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : topicPartitionOffsetAndMetadataMap.entrySet()) {\r\n        TopicPartition key = entry.getKey();\r\n        OffsetAndMetadata metadata = entry.getValue();\r\n        groupOffset.putIfAbsent(new TopicPartition(key.topic(), key.partition()), metadata.offset());\r\n    }\r\n    return groupOffset;\r\n}\r\n```","```\r\nprivate KafkaConsumer<String, String> getKafkaConsumer(String bootstrapServerConfig) {\r\n    Properties properties = new Properties();\r\n    properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServerConfig);\r\n    properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n    properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n    return new KafkaConsumer<>(properties);\r\n}\r\n```","```\r\nprivate Map<TopicPartition, Long> getProducerOffsets(Map<TopicPartition, Long> consumerGrpOffset) {\r\n    List<TopicPartition> topicPartitions = new LinkedList<>();\r\n    for (Map.Entry<TopicPartition, Long> entry : consumerGrpOffset.entrySet()) {\r\n        TopicPartition key = entry.getKey();\r\n        topicPartitions.add(new TopicPartition(key.topic(), key.partition()));\r\n    }\r\n    return kafkaConsumer.endOffsets(topicPartitions);\r\n}\r\n```","```\r\nprivate Map<TopicPartition, Long> computeLags(\r\n  Map<TopicPartition, Long> consumerGrpOffsets,\r\n  Map<TopicPartition, Long> producerOffsets) {\r\n    Map<TopicPartition, Long> lags = new HashMap<>();\r\n    for (Map.Entry<TopicPartition, Long> entry : consumerGrpOffsets.entrySet()) {\r\n        Long producerOffset = producerOffsets.get(entry.getKey());\r\n        Long consumerOffset = consumerGrpOffsets.get(entry.getKey());\r\n        long lag = Math.abs(producerOffset - consumerOffset);\r\n        lags.putIfAbsent(entry.getKey(), lag);\r\n    }\r\n    return lags;\r\n}\r\n```","```\r\npublic void analyzeLag(String groupId) throws ExecutionException, InterruptedException {\r\n    Map<TopicPartition, Long> consumerGrpOffsets = getConsumerGrpOffsets(groupId);\r\n    Map<TopicPartition, Long> producerOffsets = getProducerOffsets(consumerGrpOffsets);\r\n    Map<TopicPartition, Long> lags = computeLags(consumerGrpOffsets, producerOffsets);\r\n    for (Map.Entry<TopicPartition, Long> lagEntry : lags.entrySet()) {\r\n        String topic = lagEntry.getKey().topic();\r\n        int partition = lagEntry.getKey().partition();\r\n        Long lag = lagEntry.getValue();\r\n        System.out.printf(\"Time=%s | Lag for topic = %s, partition = %s is %d\\n\",\r\n          MonitoringUtil.time(),\r\n          topic,\r\n          partition,\r\n          lag);\r\n    }\r\n}\r\n```","```\r\n@Scheduled(fixedDelay = 5000L)\r\npublic void liveLagAnalysis() throws ExecutionException, InterruptedException {\r\n    lagAnalyzerService.analyzeLag(groupId);\r\n}\r\n```","```\r\nmonitor.producer.simulate=true\r\nmonitor.consumer.simulate=true\r\n```","```\r\npublic static final Date startTime = new Date();\r\npublic static final Date endTime = new Date(startTime.getTime() + 30 * 1000);\r\n\r\npublic static String time() {\r\n    DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy/MM/dd HH:mm:ss\");\r\n    LocalDateTime now = LocalDateTime.now();\r\n    String date = dtf.format(now);\r\n    return date;\r\n}\r\n```","```\r\npublic ConsumerFactory<String, String> consumerFactory(String groupId) {\r\n    Map<String, Object> props = new HashMap<>();\r\n    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);\r\n    if (enabled) {\r\n        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\r\n    } else {\r\n        props.put(ConsumerConfig.GROUP_ID_CONFIG, simulateGroupId);\r\n    }\r\n    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\r\n    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\r\n    props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 0);\r\n    return new DefaultKafkaConsumerFactory<>(props);\r\n}\r\n\r\n@Bean\r\npublic ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {\r\n    ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();\r\n    if (enabled) {\r\n        factory.setConsumerFactory(consumerFactory(groupId));\r\n    } else {\r\n        factory.setConsumerFactory(consumerFactory(simulateGroupId));\r\n    }\r\n    return factory;\r\n} \r\n```","```\r\n@Bean\r\npublic ProducerFactory<String, String> producerFactory() {\r\n    Map<String, Object> configProps = new HashMap<>();\r\n    configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);\r\n    configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\r\n    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\r\n    return new DefaultKafkaProducerFactory<>(configProps);\r\n}\r\n\r\n@Bean\r\npublic KafkaTemplate<String, String> kafkaTemplate() {\r\n    return new KafkaTemplate<>(producerFactory());\r\n}\r\n```","```\r\n@KafkaListener(\r\n  topics = \"${monitor.topic.name}\",\r\n  containerFactory = \"kafkaListenerContainerFactory\",\r\n  autoStartup = \"${monitor.consumer.simulate}\")\r\npublic void listen(String message) throws InterruptedException {\r\n    Thread.sleep(10L);\r\n}\r\n```","```\r\n@Scheduled(fixedDelay = 1L, initialDelay = 5L)\r\npublic void sendMessage() throws ExecutionException, InterruptedException {\r\n    if (enabled) {\r\n        if (endTime.after(new Date())) {\r\n            String message = \"msg-\" + time();\r\n            SendResult<String, String> result = kafkaTemplate.send(topicName, message).get();\r\n        }\r\n    }\r\n}\r\n```","```\r\npublic static void main(String[] args) {\r\n    SpringApplication.run(LagAnalyzerApplication.class, args);\r\n    while (true) ;\r\n}\r\n```","```\r\nTime=2021/06/06 11:07:24 | Lag for topic = baeldungTopic, partition = 0 is 93\r\nTime=2021/06/06 11:07:29 | Lag for topic = baeldungTopic, partition = 0 is 290\r\nTime=2021/06/06 11:07:34 | Lag for topic = baeldungTopic, partition = 0 is 776\r\nTime=2021/06/06 11:07:39 | Lag for topic = baeldungTopic, partition = 0 is 1159\r\nTime=2021/06/06 11:07:44 | Lag for topic = baeldungTopic, partition = 0 is 1559\r\nTime=2021/06/06 11:07:49 | Lag for topic = baeldungTopic, partition = 0 is 2015\r\nTime=2021/06/06 11:07:54 | Lag for topic = baeldungTopic, partition = 0 is 1231\r\nTime=2021/06/06 11:07:59 | Lag for topic = baeldungTopic, partition = 0 is 731\r\nTime=2021/06/06 11:08:04 | Lag for topic = baeldungTopic, partition = 0 is 231\r\nTime=2021/06/06 11:08:09 | Lag for topic = baeldungTopic, partition = 0 is 0\r\n```"]
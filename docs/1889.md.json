["```\r\n<dependency>\r\n    <groupId>org.apache.spark</groupId>\r\n    <artifactId>spark-mllib_2.11</artifactId>\r\n    <version>2.4.3</version>\r\n    <scope>provided</scope>\r\n</dependency>\r\n```","```\r\nSparkConf conf = new SparkConf()\r\n  .setAppName(\"Main\")\r\n  .setMaster(\"local[2]\");\r\nJavaSparkContext sc = new JavaSparkContext(conf);\r\n```","```\r\nString dataFile = \"data\\\\iris.data\";\r\nJavaRDD<String> data = sc.textFile(dataFile);\r\n```","```\r\nJavaRDD<Vector> inputData = data\r\n  .map(line -> {\r\n      String[] parts = line.split(\",\");\r\n      double[] v = new double[parts.length - 1];\r\n      for (int i = 0; i < parts.length - 1; i++) {\r\n          v[i] = Double.parseDouble(parts[i]);\r\n      }\r\n      return Vectors.dense(v);\r\n});\r\n```","```\r\nMap<String, Integer> map = new HashMap<>();\r\nmap.put(\"Iris-setosa\", 0);\r\nmap.put(\"Iris-versicolor\", 1);\r\nmap.put(\"Iris-virginica\", 2);\r\n\r\nJavaRDD<LabeledPoint> labeledData = data\r\n  .map(line -> {\r\n      String[] parts = line.split(\",\");\r\n      double[] v = new double[parts.length - 1];\r\n      for (int i = 0; i < parts.length - 1; i++) {\r\n          v[i] = Double.parseDouble(parts[i]);\r\n      }\r\n      return new LabeledPoint(map.get(parts[parts.length - 1]), Vectors.dense(v));\r\n});\r\n```","```\r\nMultivariateStatisticalSummary summary = Statistics.colStats(inputData.rdd());\r\nSystem.out.println(\"Summary Mean:\");\r\nSystem.out.println(summary.mean());\r\nSystem.out.println(\"Summary Variance:\");\r\nSystem.out.println(summary.variance());\r\nSystem.out.println(\"Summary Non-zero:\");\r\nSystem.out.println(summary.numNonzeros());\r\n```","```\r\nSummary Mean:\r\n[5.843333333333332,3.0540000000000003,3.7586666666666666,1.1986666666666668]\r\nSummary Variance:\r\n[0.6856935123042509,0.18800402684563744,3.113179418344516,0.5824143176733783]\r\nSummary Non-zero:\r\n[150.0,150.0,150.0,150.0]\r\n```","```\r\nMatrix correlMatrix = Statistics.corr(inputData.rdd(), \"pearson\");\r\nSystem.out.println(\"Correlation Matrix:\");\r\nSystem.out.println(correlMatrix.toString());\r\n```","```\r\nCorrelation Matrix:\r\n1.0                   -0.10936924995064387  0.8717541573048727   0.8179536333691672   \r\n-0.10936924995064387  1.0                   -0.4205160964011671  -0.3565440896138163  \r\n0.8717541573048727    -0.4205160964011671   1.0                  0.9627570970509661   \r\n0.8179536333691672    -0.3565440896138163   0.9627570970509661   1.0\r\n```","```\r\nJavaRDD<LabeledPoint>[] splits = parsedData.randomSplit(new double[] { 0.8, 0.2 }, 11L);\r\nJavaRDD<LabeledPoint> trainingData = splits[0];\r\nJavaRDD<LabeledPoint> testData = splits[1];\r\n```","```\r\nLogisticRegressionModel model = new LogisticRegressionWithLBFGS()\r\n  .setNumClasses(3)\r\n  .run(trainingData.rdd());\r\n```","```\r\nJavaPairRDD<Object, Object> predictionAndLabels = testData\r\n  .mapToPair(p -> new Tuple2<>(model.predict(p.features()), p.label()));\r\nMulticlassMetrics metrics = new MulticlassMetrics(predictionAndLabels.rdd());\r\ndouble accuracy = metrics.accuracy();\r\nSystem.out.println(\"Model Accuracy on Test Data: \" + accuracy);\r\n```","```\r\nModel Accuracy on Test Data: 0.9310344827586207\r\n```","```\r\nmodel.save(sc, \"model\\\\logistic-regression\");\r\nLogisticRegressionModel sameModel = LogisticRegressionModel\r\n  .load(sc, \"model\\\\logistic-regression\");\r\nVector newData = Vectors.dense(new double[]{1,1,1,1});\r\ndouble prediction = sameModel.predict(newData);\r\nSystem.out.println(\"Model Prediction on New Data = \" + prediction);\r\n```","```\r\nModel Prediction on New Data = 2.0\r\n```"]
["```\r\n<dependency>\r\n    <groupId>org.apache.lucene</groupId>\r\n    <artifactId>lucene-core</artifactId>\r\n    <version>7.4.0</version>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.apache.lucene</groupId>\r\n    <artifactId>lucene-queryparser</artifactId>\r\n    <version>7.4.0</version>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.apache.lucene</groupId>\r\n    <artifactId>lucene-analyzers-common</artifactId>\r\n    <version>7.4.0</version>\r\n</dependency>\r\n```","```\r\npublic List<String> analyze(String text, Analyzer analyzer) throws IOException{\r\n    List<String> result = new ArrayList<String>();\r\n    TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, text);\r\n    CharTermAttribute attr = tokenStream.addAttribute(CharTermAttribute.class);\r\n    tokenStream.reset();\r\n    while(tokenStream.incrementToken()) {\r\n       result.add(attr.toString());\r\n    }       \r\n    return result;\r\n}\r\n```","```\r\nprivate static final String SAMPLE_TEXT\r\n  = \"This is baeldung.com Lucene Analyzers test\";\r\n\r\n@Test\r\npublic void whenUseStandardAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new StandardAnalyzer());\r\n\r\n    assertThat(result, \r\n      contains(\"baeldung.com\", \"lucene\", \"analyzers\",\"test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseStopAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new StopAnalyzer());\r\n\r\n    assertThat(result, \r\n      contains(\"baeldung\", \"com\", \"lucene\", \"analyzers\", \"test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseSimpleAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new SimpleAnalyzer());\r\n\r\n    assertThat(result, \r\n      contains(\"this\", \"is\", \"baeldung\", \"com\", \"lucene\", \"analyzers\", \"test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseWhiteSpaceAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new WhitespaceAnalyzer());\r\n\r\n    assertThat(result, \r\n      contains(\"This\", \"is\", \"baeldung.com\", \"Lucene\", \"Analyzers\", \"test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseKeywordAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new KeywordAnalyzer());\r\n\r\n    assertThat(result, contains(\"This is baeldung.com Lucene Analyzers test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseEnglishAnalyzer_thenAnalyzed() throws IOException {\r\n    List<String> result = analyze(SAMPLE_TEXT, new EnglishAnalyzer());\r\n\r\n    assertThat(result, contains(\"baeldung.com\", \"lucen\", \"analyz\", \"test\"));\r\n}\r\n```","```\r\n@Test\r\npublic void whenUseCustomAnalyzerBuilder_thenAnalyzed() throws IOException {\r\n    Analyzer analyzer = CustomAnalyzer.builder()\r\n      .withTokenizer(\"standard\")\r\n      .addTokenFilter(\"lowercase\")\r\n      .addTokenFilter(\"stop\")\r\n      .addTokenFilter(\"porterstem\")\r\n      .addTokenFilter(\"capitalization\")\r\n      .build();\r\n    List<String> result = analyze(SAMPLE_TEXT, analyzer);\r\n\r\n    assertThat(result, contains(\"Baeldung.com\", \"Lucen\", \"Analyz\", \"Test\"));\r\n}\r\n```","```\r\npublic class MyCustomAnalyzer extends Analyzer {\r\n\r\n    @Override\r\n    protected TokenStreamComponents createComponents(String fieldName) {\r\n        StandardTokenizer src = new StandardTokenizer();\r\n        TokenStream result = new StandardFilter(src);\r\n        result = new LowerCaseFilter(result);\r\n        result = new StopFilter(result,  StandardAnalyzer.STOP_WORDS_SET);\r\n        result = new PorterStemFilter(result);\r\n        result = new CapitalizationFilter(result);\r\n        return new TokenStreamComponents(src, result);\r\n    }\r\n}\r\n```","```\r\n@Test\r\npublic void givenTermQuery_whenUseCustomAnalyzer_thenCorrect() {\r\n    InMemoryLuceneIndex luceneIndex = new InMemoryLuceneIndex(\r\n      new RAMDirectory(), new MyCustomAnalyzer());\r\n    luceneIndex.indexDocument(\"introduction\", \"introduction to lucene\");\r\n    luceneIndex.indexDocument(\"analyzers\", \"guide to lucene analyzers\");\r\n    Query query = new TermQuery(new Term(\"body\", \"Introduct\"));\r\n\r\n    List<Document> documents = luceneIndex.searchIndex(query);\r\n    assertEquals(1, documents.size());\r\n}\r\n```","```\r\nMap<String,Analyzer> analyzerMap = new HashMap<>();\r\nanalyzerMap.put(\"title\", new MyCustomAnalyzer());\r\nanalyzerMap.put(\"body\", new EnglishAnalyzer());\r\n```","```\r\nPerFieldAnalyzerWrapper wrapper = new PerFieldAnalyzerWrapper(\r\n  new StandardAnalyzer(), analyzerMap);\r\n```","```\r\n@Test\r\npublic void givenTermQuery_whenUsePerFieldAnalyzerWrapper_thenCorrect() {\r\n    InMemoryLuceneIndex luceneIndex = new InMemoryLuceneIndex(new RAMDirectory(), wrapper);\r\n    luceneIndex.indexDocument(\"introduction\", \"introduction to lucene\");\r\n    luceneIndex.indexDocument(\"analyzers\", \"guide to lucene analyzers\");\r\n\r\n    Query query = new TermQuery(new Term(\"body\", \"introduct\"));\r\n    List<Document> documents = luceneIndex.searchIndex(query);\r\n    assertEquals(1, documents.size());\r\n\r\n    query = new TermQuery(new Term(\"title\", \"Introduct\"));\r\n    documents = luceneIndex.searchIndex(query);\r\n    assertEquals(1, documents.size());\r\n}\r\n```"]
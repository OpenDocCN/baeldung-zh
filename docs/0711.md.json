["```\r\n<dependency>\r\n    <groupId>org.apache.crunch</groupId>\r\n    <artifactId>crunch-core</artifactId>\r\n    <version>0.15.0</version>\r\n</dependency>\r\n```","```\r\n<dependency>\r\n    <groupId>org.apache.hadoop</groupId>\r\n    <artifactId>hadoop-client</artifactId>\r\n    <version>2.2.0</version>\r\n    <scope>provided</scope>\r\n</dependency>\r\n```","```\r\nmvn archetype:generate -Dfilter=org.apache.crunch:crunch-archetype \r\n```","```\r\nPipeline pipeline = MemPipeline.getInstance();\r\n```","```\r\nPipeline pipeline = new MRPipeline(WordCount.class, getConf());\r\n```","```\r\nPCollection<String> lines = pipeline.readTextFile(inputPath);\r\n```","```\r\n@Test\r\npublic void givenPipeLine_whenTextFileRead_thenExpectedNumberOfRecordsRead() {\r\n    Pipeline pipeline = MemPipeline.getInstance();\r\n    PCollection<String> lines = pipeline.readTextFile(INPUT_FILE_PATH);\r\n\r\n    assertEquals(21, lines.asCollection()\r\n      .getValue()\r\n      .size());\r\n}\r\n```","```\r\npublic class Tokenizer extends DoFn<String, String> {\r\n    private static final Splitter SPLITTER = Splitter\r\n      .onPattern(\"\\\\s+\")\r\n      .omitEmptyStrings();\r\n\r\n    @Override\r\n    public void process(String line, Emitter<String> emitter) {\r\n        for (String word : SPLITTER.split(line)) {\r\n            emitter.emit(word);\r\n        }\r\n    }\r\n} \r\n```","```\r\n@RunWith(MockitoJUnitRunner.class)\r\npublic class TokenizerUnitTest {\r\n\r\n    @Mock\r\n    private Emitter<String> emitter;\r\n\r\n    @Test\r\n    public void givenTokenizer_whenLineProcessed_thenOnlyExpectedWordsEmitted() {\r\n        Tokenizer splitter = new Tokenizer();\r\n        splitter.process(\"  hello  world \", emitter);\r\n\r\n        verify(emitter).emit(\"hello\");\r\n        verify(emitter).emit(\"world\");\r\n        verifyNoMoreInteractions(emitter);\r\n    }\r\n}\r\n```","```\r\nPCollection<String> words = lines.parallelDo(new Tokenizer(), Writables.strings()); \r\n```","```\r\npublic class StopWordFilter extends FilterFn<String> {\r\n\r\n    // English stop words, borrowed from Lucene.\r\n    private static final Set<String> STOP_WORDS = ImmutableSet\r\n      .copyOf(new String[] { \"a\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\",\r\n        \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\",\r\n        \"or\", \"s\", \"such\", \"t\", \"that\", \"the\", \"their\", \"then\", \"there\",\r\n        \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\" });\r\n\r\n    @Override\r\n    public boolean accept(String word) {\r\n        return !STOP_WORDS.contains(word);\r\n    }\r\n}\r\n```","```\r\npublic class StopWordFilterUnitTest {\r\n\r\n    @Test\r\n    public void givenFilter_whenStopWordPassed_thenFalseReturned() {\r\n        FilterFn<String> filter = new StopWordFilter();\r\n\r\n        assertFalse(filter.accept(\"the\"));\r\n        assertFalse(filter.accept(\"a\"));\r\n    }\r\n\r\n    @Test\r\n    public void givenFilter_whenNonStopWordPassed_thenTrueReturned() {\r\n        FilterFn<String> filter = new StopWordFilter();\r\n\r\n        assertTrue(filter.accept(\"Hello\"));\r\n        assertTrue(filter.accept(\"World\"));\r\n    }\r\n\r\n    @Test\r\n    public void givenWordCollection_whenFiltered_thenStopWordsRemoved() {\r\n        PCollection<String> words = MemPipeline\r\n          .collectionOf(\"This\", \"is\", \"a\", \"test\", \"sentence\");\r\n        PCollection<String> noStopWords = words.filter(new StopWordFilter());\r\n\r\n        assertEquals(ImmutableList.of(\"This\", \"test\", \"sentence\"),\r\n         Lists.newArrayList(noStopWords.materialize()));\r\n    }\r\n}\r\n```","```\r\nPCollection<String> noStopWords = words.filter(new StopWordFilter());\r\n```","```\r\n// The count method applies a series of Crunch primitives and returns\r\n// a map of the unique words in the input PCollection to their counts.\r\nPTable<String, Long> counts = noStopWords.count();\r\n```","```\r\nvoid write(PCollection<?> collection, Target target);\r\n\r\nvoid write(PCollection<?> collection, Target target,\r\n  Target.WriteMode writeMode);\r\n\r\n<T> void writeTextFile(PCollection<T> collection, String pathName);\r\n```","```\r\npipeline.writeTextFile(counts, outputPath); \r\n```","```\r\nPipelineResult result = pipeline.done(); \r\n```","```\r\npublic int run(String[] args) throws Exception {\r\n    String inputPath = args[0];\r\n    String outputPath = args[1];\r\n\r\n    // Create an object to coordinate pipeline creation and execution.\r\n    Pipeline pipeline = new MRPipeline(WordCount.class, getConf());\r\n\r\n    // Reference a given text file as a collection of Strings.\r\n    PCollection<String> lines = pipeline.readTextFile(inputPath);\r\n\r\n    // Define a function that splits each line in a PCollection of Strings into\r\n    // a PCollection made up of the individual words in the file.\r\n    // The second argument sets the serialization format.\r\n    PCollection<String> words = lines.parallelDo(new Tokenizer(), Writables.strings());\r\n\r\n    // Take the collection of words and remove known stop words.\r\n    PCollection<String> noStopWords = words.filter(new StopWordFilter());\r\n\r\n    // The count method applies a series of Crunch primitives and returns\r\n    // a map of the unique words in the input PCollection to their counts.\r\n    PTable<String, Long> counts = noStopWords.count();\r\n\r\n    // Instruct the pipeline to write the resulting counts to a text file.\r\n    pipeline.writeTextFile(counts, outputPath);\r\n\r\n    // Execute the pipeline as a MapReduce.\r\n    PipelineResult result = pipeline.done();\r\n\r\n    return result.succeeded() ? 0 : 1;\r\n}\r\n```","```\r\npublic class WordCount extends Configured implements Tool {\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        ToolRunner.run(new Configuration(), new WordCount(), args);\r\n    }\r\n```","```\r\nmvn package \r\n```","```\r\nhadoop jar target/crunch-1.0-SNAPSHOT-job.jar <input file path> <output directory>\r\n```","```\r\n[Add,1]\r\n[Added,1]\r\n[Admiration,1]\r\n[Admitting,1]\r\n[Allowance,1]\r\n```"]